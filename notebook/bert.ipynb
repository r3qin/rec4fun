{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9ccaf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast, LineByLineTextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import BertConfig, BertForMaskedLM\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39bf740",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9c30e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1517085</td>\n",
       "      <td>1659304800025</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1563459</td>\n",
       "      <td>1659304904511</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1309446</td>\n",
       "      <td>1659367439426</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>16246</td>\n",
       "      <td>1659367719997</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1781822</td>\n",
       "      <td>1659367871344</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session      aid             ts    type\n",
       "0        0  1517085  1659304800025  clicks\n",
       "1        0  1563459  1659304904511  clicks\n",
       "2        0  1309446  1659367439426  clicks\n",
       "3        0    16246  1659367719997  clicks\n",
       "4        0  1781822  1659367871344  clicks"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/train_sessions.jsonl'\n",
    "  \n",
    "train_sessions = pd.DataFrame()\n",
    "chunks = pd.read_json(data_path, lines=True, chunksize=100_000)\n",
    "\n",
    "for e, chunk in enumerate(chunks):\n",
    "    event_dict = {\n",
    "        'session': [],\n",
    "        'aid': [],\n",
    "        'ts': [],\n",
    "        'type': [],\n",
    "    }\n",
    "    if e < 2:\n",
    "        # train_sessions = pd.concat([train_sessions, chunk])\n",
    "        for session, events in zip(chunk['session'].tolist(), chunk['events'].tolist()):\n",
    "            for event in events:\n",
    "                event_dict['session'].append(session)\n",
    "                event_dict['aid'].append(event['aid'])\n",
    "                event_dict['ts'].append(event['ts'])\n",
    "                event_dict['type'].append(event['type'])\n",
    "        chunk_session = pd.DataFrame(event_dict)\n",
    "        train_sessions = pd.concat([train_sessions, chunk_session])\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "train_sessions = train_sessions.reset_index(drop=True)\n",
    "train_sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a445e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12383433</td>\n",
       "      <td>1542913</td>\n",
       "      <td>1661551200081</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12383434</td>\n",
       "      <td>8211</td>\n",
       "      <td>1661551200511</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12383435</td>\n",
       "      <td>940546</td>\n",
       "      <td>1661551201055</td>\n",
       "      <td>carts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12383435</td>\n",
       "      <td>45443</td>\n",
       "      <td>1661551213043</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12383435</td>\n",
       "      <td>1769360</td>\n",
       "      <td>1661551246239</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session      aid             ts    type\n",
       "0  12383433  1542913  1661551200081  clicks\n",
       "1  12383434     8211  1661551200511  clicks\n",
       "2  12383435   940546  1661551201055   carts\n",
       "3  12383435    45443  1661551213043  clicks\n",
       "4  12383435  1769360  1661551246239  clicks"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/test_sessions.jsonl'\n",
    "  \n",
    "test_sessions = pd.DataFrame()\n",
    "chunks = pd.read_json(data_path, lines=True, chunksize=100_000)\n",
    "\n",
    "for e, chunk in enumerate(chunks):\n",
    "    event_dict = {\n",
    "        'session': [],\n",
    "        'aid': [],\n",
    "        'ts': [],\n",
    "        'type': [],\n",
    "    }\n",
    "    if e < 2:\n",
    "        # train_sessions = pd.concat([train_sessions, chunk])\n",
    "        for session, events in zip(chunk['session'].tolist(), chunk['events'].tolist()):\n",
    "            for event in events:\n",
    "                event_dict['session'].append(session)\n",
    "                event_dict['aid'].append(event['aid'])\n",
    "                event_dict['ts'].append(event['ts'])\n",
    "                event_dict['type'].append(event['type'])\n",
    "        chunk_session = pd.DataFrame(event_dict)\n",
    "        test_sessions = pd.concat([test_sessions, chunk_session])\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "test_sessions = test_sessions.reset_index(drop=True)\n",
    "test_sessions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc02244d",
   "metadata": {},
   "source": [
    "## Training sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b2fb3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1517085, 1563459, 1309446, 16246, 1781822, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[424964, 1492293, 910862, 1491172, 424964, 151...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[763743, 137492, 504789, 137492, 795863, 37834...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[1425967, 1343406, 1425967, 1343406, 1815570, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[613619, 298827, 383828, 255379, 1838173, 1453...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session                                                aid\n",
       "0        0  [1517085, 1563459, 1309446, 16246, 1781822, 11...\n",
       "1        1  [424964, 1492293, 910862, 1491172, 424964, 151...\n",
       "2        2  [763743, 137492, 504789, 137492, 795863, 37834...\n",
       "3        3  [1425967, 1343406, 1425967, 1343406, 1815570, ...\n",
       "4        4  [613619, 298827, 383828, 255379, 1838173, 1453..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aid_seq = train_sessions.sort_values([\"session\", \"ts\"]).reset_index(drop=True)\n",
    "aid_seq[\"aid_2\"] = aid_seq.aid.shift(1)\n",
    "aid_seq = aid_seq[aid_seq.aid != aid_seq.aid_2]\n",
    "aid_seq = aid_seq[[\"session\", \"aid\", \"ts\", \"type\"]]\n",
    "aid_seq[\"aid\"] = aid_seq[\"aid\"].astype(str)\n",
    "aid_seq = aid_seq.groupby([\"session\"]).agg(list)[\"aid\"].reset_index()\n",
    "aid_seq = aid_seq[(aid_seq.aid.apply(len) > 1)].reset_index(drop=True)\n",
    "aid_seq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61e95d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/bert_seq.txt\", 'w') as f:\n",
    "    for aid_list in aid_seq.aid:\n",
    "        print(\" \".join(aid_list), file = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977fa597",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d1fab",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53e50f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = WhitespaceSplit()\n",
    "trainer = WordLevelTrainer(\n",
    "    min_frequency = 0,\n",
    "    vocab_size = 30522,\n",
    "    special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"]\n",
    ")\n",
    "tokenizer.train(files=[\"../data/bert_seq.txt\"], trainer=trainer)\n",
    "tokenizer.post_processor = BertProcessing(\n",
    "    (\"[SEP]\", 2),\n",
    "    (\"[CLS]\", 1)\n",
    ")\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    unk_token = \"[UNK]\",\n",
    "    cls_token = \"[CLS]\",\n",
    "    sep_token = \"[SEP]\",\n",
    "    pad_token = \"[PAD]\",\n",
    "    mask_token = \"[MASK]\",\n",
    "    tokenizer_object=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a71983d",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66b32286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating features from dataset file at ../data/bert_seq.txt\n"
     ]
    }
   ],
   "source": [
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer = tokenizer,\n",
    "    file_path = \"../data/bert_seq.txt\",\n",
    "    block_size = 512  # maximum sequence length\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d065db2b",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b996b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config= BertConfig(\n",
    "    vocab_size = 30522,\n",
    "    hidden_size = 64,\n",
    "    intermediate_size = 128,\n",
    "    num_hidden_layers = 4, \n",
    "    num_attention_heads = 4,\n",
    "    max_position_embeddings = 512\n",
    ")\n",
    "model = BertForMaskedLM(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618ab83",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6588e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = '../src/models',\n",
    "    overwrite_output_dir = True,\n",
    "    num_train_epochs = 1,\n",
    "    per_device_train_batch_size = 64,\n",
    "    save_steps = 10_000,\n",
    "    save_total_limit = 2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    data_collator = data_collator,\n",
    "    train_dataset = dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55907511",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ca764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
